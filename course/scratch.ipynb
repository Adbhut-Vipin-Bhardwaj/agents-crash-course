{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb394c4-7ec0-4878-85ef-fe5a41a6be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1cd0ca-1a44-4029-aa2f-95d3c3495125",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./openai_api_key.txt\", \"r\") as f:\n",
    "    openai_api_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88cba8-2967-4c96-b6e7-3c71c5a34fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6a823-6da7-45a2-b542-3f9822e5f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./example.md', 'r', encoding='utf-8') as f:\n",
    "    post = frontmatter.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87bc3e7-1fef-4505-a4d4-a8493c943e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "post.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bda243-3d88-484b-ac74-3aa2acd07057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(Markdown(post.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e63209-25b6-4005-bd0d-3eafbc033f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbe702-6cba-4423-b32a-27d963cef27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85faf98-60a6-47ca-b918-dc935462caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeload.github.com/DataTalksClub/faq/zip/refs/heads/main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78642988-7291-49f7-a022-c1c3fce18b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af43b83-d4c5-477c-a6b4-afd591d8ecb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ddad04-b409-4f66-8c6e-9d3c26d58737",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_data = []\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:\n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename.lower()\n",
    "    \n",
    "        # Only process markdown files\n",
    "        if not (filename.endswith('.md') or filename.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        # Read and parse each file\n",
    "        with zf.open(file_info) as f_in:\n",
    "            content = f_in.read()\n",
    "            post = frontmatter.loads(content)\n",
    "            data = post.to_dict()\n",
    "            data['filename'] = filename\n",
    "            repository_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d64d8a-929b-49df-a972-d81465f59d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(repository_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8e104-c157-4595-be87-5b0f4dd99f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edbc4c-d758-4408-8f0e-7ab8db2cba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:\n",
    "        for file_info in zf.infolist():\n",
    "            filename = file_info.filename\n",
    "            filename_lower = filename.lower()\n",
    "\n",
    "            if not (filename_lower.endswith('.md') \n",
    "                or filename_lower.endswith('.mdx')):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with zf.open(file_info) as f_in:\n",
    "                    content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                    post = frontmatter.loads(content)\n",
    "                    data = post.to_dict()\n",
    "                    data['filename'] = filename\n",
    "                    repository_data.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return repository_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b2ed0-d42b-44cc-8dad-7b07eb1b10e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827b87a-76c1-424f-b004-dfdb320fdf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "evidently_docs = read_repo_data('evidentlyai', 'docs')\n",
    "\n",
    "print(f\"FAQ documents: {len(dtc_faq)}\")\n",
    "print(f\"Evidently documents: {len(evidently_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2368f56-10db-4f92-911f-52e14ab09470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62862724-d7c2-47e4-9c74-019083ac7f82",
   "metadata": {},
   "source": [
    "### Simple chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6506097-1147-48c9-af7f-1579e00804f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d691f9c-3410-4aa9-80eb-61ca303d9e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5784e61-98dc-4a89-9805-11d901730272",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evidently_docs[45][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66614ae-6cb1-4a7d-827c-ffa729154012",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop(\"content\")\n",
    "    chunks = sliding_window(doc_content, 2000, 1000)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    evidently_chunks.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb16993-cc24-40cc-9c38-a5b828f71e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c843b7-4543-42fb-aab2-650f41019c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evidently_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5985fa2-919a-4aee-ac66-93cf460e479f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4dde5e9-e4c1-4e8e-b647-eb3998743a28",
   "metadata": {},
   "source": [
    "### Splitting by Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db700c2f-9830-4898-b426-f6d9a5248e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_markdown_by_level(text, level=2):\n",
    "    \"\"\"\n",
    "    Split markdown text by a specific header level.\n",
    "    \n",
    "    :param text: Markdown text as a string\n",
    "    :param level: Header level to split on\n",
    "    :return: List of sections as strings\n",
    "    \"\"\"\n",
    "    # This regex matches markdown headers\n",
    "    # For level 2, it matches lines starting with \"## \"\n",
    "    header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "    pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "\n",
    "    # Split and keep the headers\n",
    "    parts = pattern.split(text)\n",
    "\n",
    "    sections = []\n",
    "    for i in range(1, len(parts), 3):\n",
    "        # We step by 3 because regex.split() with\n",
    "        # capturing groups returns:\n",
    "        # [before_match, group1, group2, after_match, ...]\n",
    "        # here group1 is \"## \", group2 is the header text\n",
    "        header = parts[i] + parts[i+1]  # \"## \" + \"Title\"\n",
    "        header = header.strip()\n",
    "\n",
    "        # Get the content after this header\n",
    "        content = \"\"\n",
    "        if i+2 < len(parts):\n",
    "            content = parts[i+2].strip()\n",
    "\n",
    "        if content:\n",
    "            section = f'{header}\\n\\n{content}'\n",
    "        else:\n",
    "            section = header\n",
    "        sections.append(section)\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad35be0-fe2c-47f7-8911-f5b92cea5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop(\"content\")\n",
    "    sections = split_markdown_by_level(doc_content, level=2)\n",
    "\n",
    "    for section in sections:\n",
    "        section_copy = doc_copy.copy()\n",
    "        section_copy[\"section\"] = section\n",
    "        evidently_chunks.extend(section_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2633c-bbfb-428d-9e01-416ce9fdabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evidently_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1fbf9-c05d-467c-9085-970feacfaa84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a307d7cc-4d80-415a-9053-a412a073ccc1",
   "metadata": {},
   "source": [
    "### Chunking with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77b3c5-fa0f-462c-bfd7-89d2b723904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model='gpt-4o-mini',\n",
    "        input=messages\n",
    "    )\n",
    "\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079ebab-3752-4f1f-a7cb-d9def943689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Split the provided document into logical sections\n",
    "that make sense for a Q&A system.\n",
    "\n",
    "Each section should be self-contained and cover\n",
    "a specific topic or concept.\n",
    "\n",
    "<DOCUMENT>\n",
    "{document}\n",
    "</DOCUMENT>\n",
    "\n",
    "Use this format:\n",
    "\n",
    "## Section Name\n",
    "\n",
    "Section content with all relevant details\n",
    "\n",
    "---\n",
    "\n",
    "## Another Section Name\n",
    "\n",
    "Another section content\n",
    "\n",
    "---\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f96ce4-0e3d-4b95-b45b-0905e087429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intelligent_chunking(text):\n",
    "    prompt = prompt_template.format(document=text)\n",
    "    response = llm(prompt)\n",
    "    sections = response.split(\"---\")\n",
    "    sections = [s.strip() for s in sections if s.strip()]\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb63831-ad99-46c0-b1a7-831ba634b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in tqdm(evidently_docs):\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop(\"content\")\n",
    "    if not doc_content:\n",
    "        continue\n",
    "\n",
    "    sections = intelligent_chunking(doc_content)\n",
    "\n",
    "    for section in sections:\n",
    "        section_copy = doc_copy.copy()\n",
    "        section_copy[\"section\"] = section\n",
    "        evidently_chunks.append(section_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df87c51-e05b-480c-a796-916c81f728bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71799a41-d837-4b34-b424-e6a15d79d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evidently_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a97d5b-d529-4a71-bfb3-1bdc1a7d3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(evidently_chunks[4][\"section\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef5165-8efa-4fed-81e5-35bce4ed0c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08ba86-85b5-486c-9af5-976f83f0a774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059c6e3-c7e0-40ea-a67e-b9b09e5de004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
